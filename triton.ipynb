{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcee4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.08-py3: Pulling from nvidia/tritonserver\r\n",
      "Digest: sha256:6a1ef84e93327fef53ac11379fa4e53082c9e228de5db24e0abdfc5aff5676cf\r\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:21.08-py3\r\n",
      "nvcr.io/nvidia/tritonserver:21.08-py3\r\n"
     ]
    }
   ],
   "source": [
    "!docker pull nvcr.io/nvidia/tritonserver:21.08-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dc76671",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf triton_models\n",
    "!mkdir -p triton_models\n",
    "!mkdir -p triton_models/resnet1/\n",
    "!mkdir -p triton_models/resnet1/1/\n",
    "!cp traced_resnet_model.pt triton_models/resnet1/1/model.pt\n",
    "\n",
    "!mkdir -p triton_models/resnet2/\n",
    "!mkdir -p triton_models/resnet2/1/\n",
    "!cp traced_resnet_model.pt triton_models/resnet2/1/model.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "123403a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing triton_models/resnet1/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile triton_models/resnet1/config.pbtxt  \n",
    "name: \"resnet1\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "input [\n",
    " {\n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32 \n",
    "    dims: [-1, 3, 224, 224]\n",
    "  } \n",
    "]\n",
    "output {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [1000]\n",
    "  }\n",
    "\n",
    "instance_group [\n",
    "  {\n",
    "      kind:KIND_GPU\n",
    "  } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "707789fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing triton_models/resnet2/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile triton_models/resnet2/config.pbtxt  \n",
    "name: \"resnet2\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "input [\n",
    " {\n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32 \n",
    "    dims: [-1, 3, 224, 224]\n",
    "  } \n",
    "]\n",
    "output {\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [1000]\n",
    "  }\n",
    "\n",
    "instance_group [\n",
    "  {\n",
    "      kind:KIND_GPU\n",
    "  } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a5bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "== Triton Inference Server ==\n",
      "=============================\n",
      "\n",
      "NVIDIA Release 21.08 (build 26170506)\n",
      "\n",
      "Copyright (c) 2018-2021, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "NOTE: Legacy NVIDIA Driver detected.  Compatibility mode ENABLED.\n",
      "\n",
      "I0922 14:35:40.258040 1 metrics.cc:290] Collecting metrics for GPU 0: Tesla V100-SXM2-16GB\n",
      "I0922 14:35:40.592443 1 libtorch.cc:1029] TRITONBACKEND_Initialize: pytorch\n",
      "I0922 14:35:40.592483 1 libtorch.cc:1039] Triton TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.592490 1 libtorch.cc:1045] 'pytorch' TRITONBACKEND API version: 1.4\n",
      "2021-09-22 14:35:40.757752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "I0922 14:35:40.805442 1 tensorflow.cc:2169] TRITONBACKEND_Initialize: tensorflow\n",
      "I0922 14:35:40.805480 1 tensorflow.cc:2179] Triton TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.805484 1 tensorflow.cc:2185] 'tensorflow' TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.805492 1 tensorflow.cc:2209] backend configuration:\n",
      "{}\n",
      "I0922 14:35:40.807136 1 onnxruntime.cc:1970] TRITONBACKEND_Initialize: onnxruntime\n",
      "I0922 14:35:40.807164 1 onnxruntime.cc:1980] Triton TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.807173 1 onnxruntime.cc:1986] 'onnxruntime' TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.831764 1 openvino.cc:1193] TRITONBACKEND_Initialize: openvino\n",
      "I0922 14:35:40.831796 1 openvino.cc:1203] Triton TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:40.831802 1 openvino.cc:1209] 'openvino' TRITONBACKEND API version: 1.4\n",
      "I0922 14:35:41.030709 1 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f8f5c000000' with size 268435456\n",
      "I0922 14:35:41.031144 1 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0922 14:35:41.033648 1 model_repository_manager.cc:1045] loading: resnet2:1\n",
      "I0922 14:35:41.133999 1 model_repository_manager.cc:1045] loading: resnet1:1\n",
      "I0922 14:35:41.134311 1 libtorch.cc:1078] TRITONBACKEND_ModelInitialize: resnet2 (version 1)\n",
      "I0922 14:35:41.135502 1 libtorch.cc:219] Optimized execution is enabled\n",
      "I0922 14:35:41.135527 1 libtorch.cc:236] Inference Mode is disabled\n",
      "I0922 14:35:41.136696 1 libtorch.cc:1119] TRITONBACKEND_ModelInstanceInitialize: resnet2_0 (device 0)\n",
      "I0922 14:35:46.289805 1 libtorch.cc:1078] TRITONBACKEND_ModelInitialize: resnet1 (version 1)\n",
      "I0922 14:35:46.290116 1 model_repository_manager.cc:1212] successfully loaded 'resnet2' version 1\n",
      "I0922 14:35:46.290431 1 libtorch.cc:219] Optimized execution is enabled\n",
      "I0922 14:35:46.290457 1 libtorch.cc:236] Inference Mode is disabled\n",
      "I0922 14:35:46.291644 1 libtorch.cc:1119] TRITONBACKEND_ModelInstanceInitialize: resnet1_0 (device 0)\n",
      "I0922 14:35:46.447755 1 model_repository_manager.cc:1212] successfully loaded 'resnet1' version 1\n",
      "I0922 14:35:46.447883 1 server.cc:504] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0922 14:35:46.447992 1 server.cc:543] \n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| Backend     | Path                                                            | Config |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "| tensorrt    | <built-in>                                                      | {}     |\n",
      "| pytorch     | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         | {}     |\n",
      "| tensorflow  | /opt/tritonserver/backends/tensorflow1/libtriton_tensorflow1.so | {}     |\n",
      "| onnxruntime | /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so | {}     |\n",
      "| openvino    | /opt/tritonserver/backends/openvino/libtriton_openvino.so       | {}     |\n",
      "+-------------+-----------------------------------------------------------------+--------+\n",
      "\n",
      "I0922 14:35:46.448053 1 server.cc:586] \n",
      "+---------+---------+--------+\n",
      "| Model   | Version | Status |\n",
      "+---------+---------+--------+\n",
      "| resnet1 | 1       | READY  |\n",
      "| resnet2 | 1       | READY  |\n",
      "+---------+---------+--------+\n",
      "\n",
      "I0922 14:35:46.448182 1 tritonserver.cc:1718] \n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                  |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                 |\n",
      "| server_version                   | 2.13.0                                                                                                                                                                                 |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics |\n",
      "| model_repository_path[0]         | /models                                                                                                                                                                                |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                              |\n",
      "| strict_model_config              | 1                                                                                                                                                                                      |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                              |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                               |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                    |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                      |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                     |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0922 14:35:46.449475 1 grpc_server.cc:4111] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0922 14:35:46.449781 1 http_server.cc:2803] Started HTTPService at 0.0.0.0:8000\n",
      "I0922 14:35:46.491345 1 http_server.cc:162] Started Metrics Service at 0.0.0.0:8002\n",
      "I0922 14:45:38.880047 1 server.cc:234] Waiting for in-flight requests to complete.\n",
      "I0922 14:45:38.880072 1 model_repository_manager.cc:1078] unloading: resnet2:1\n",
      "Signal (15) received.\n",
      "I0922 14:45:38.880194 1 model_repository_manager.cc:1078] unloading: resnet1:1\n",
      "I0922 14:45:38.880313 1 server.cc:249] Timeout 30: Found 2 live models and 0 in-flight non-inference requests\n",
      "I0922 14:45:38.880470 1 libtorch.cc:1152] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0922 14:45:38.880502 1 libtorch.cc:1152] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0922 14:45:38.887582 1 libtorch.cc:1101] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I0922 14:45:38.887592 1 libtorch.cc:1101] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I0922 14:45:38.887924 1 model_repository_manager.cc:1195] successfully unloaded 'resnet1' version 1\n",
      "I0922 14:45:38.887942 1 model_repository_manager.cc:1195] successfully unloaded 'resnet2' version 1\n",
      "I0922 14:45:39.880425 1 server.cc:249] Timeout 29: Found 0 live models and 0 in-flight non-inference requests\n"
     ]
    }
   ],
   "source": [
    "!docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v $PWD/triton_models:/models 3eb9530b33c0 tritonserver --model-repository=/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7642eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
